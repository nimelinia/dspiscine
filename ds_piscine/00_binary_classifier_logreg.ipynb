{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 08. Exercise 00\n",
    "# Binary classifier. Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will work with machine learning today and the following day. Today we will cover the basics necessary to not to get overwhelmed by too much information. The following day, will cover some more sophisticated techniques. So stay tuned!\n",
    "First of all, machine learning can be divided into supervised and unsupervised. In supervised learning, you want to predict something. In order to do that, you give the machine examples: a bunch of features and a target variable. Imagine that you want to predict whether a user would like or dislike a given movie. The features (X) can be: genre, year of creation, budget, cast, director, and so on. The target (y) will be like/dislike. That kind of task is a classification task. In classification problems, y is always categorical. If your target variable is continuous (for instance, a movie rating), it is called a regression problem.\n",
    "Unsupervised learning does not require labels (target variable). It does not forecast anything. Usually, it helps you to understand your data better. For example, clustering algorithms help you identify homogeneous groups of observations. You may find that you can divide your users into 6 groups. And for each of these groups create a special offer or a recommendation. Do not confuse this with classification. You are not trying to predict anything. You are just looking at your data.\n",
    "Besides clustering algorithms, unsupervised learning includes dimensionality reduc- tion algorithms. They help you to reduce the number of features or observations. It may be helpful if you have a lot of them, but you do not have sufficient resources. Also, they may help you to find some latent features and improve the quality of your algorithms in supervised learning.\n",
    "\n",
    "\n",
    "But enough theory! Let us try to train our first classifier. It will be a binary classifier which means that the target variable has only two unique values. You will work with the dataset from the previous days. It is absolutely normal. Actually, that is how data science works. You start from the descriptive analysis and proceed by analyzing some basic statistics. Then you go further and do explorative analysis by drawing different plots and, as a result, get a better understanding of your data. Only then do you move on to predictive analysis to forecast something.\n",
    "In this exercise imagine the following situation (which is, by the way, quite common). From some moment in the past, you realized that the more data you collect, the better. And you started saving more fields in the logs. Before, you had been collecting only the time of the commit. But from that point in time, you started collecting the date too.\n",
    "Now you need to train a classifier that can predict whether any given commit was made during working days or during weekends. Then you will be able to use the classifier to label the commits in the past when you had not been collecting the data.\n",
    "Every supervised machine learning algorithm requires at least two arguments: X and y. X is the list of features and y is the target column. But what are the features?\n",
    "As you no doubt recall, we only have logs like this 2020-04-17 05:19:02.744528. How can we use this to predict the type of weekday? That is the creative part of the work. It is called feature engineering. You need to extract these features from the logs. What could it be? Remember that the observation in this task is a day? So, we need to extract something that can somehow characterize days. What could it be? It may be, for example, the number of commits during the day. It may be the number of commits before midday and afterward. Or it may be also the percentage of commits made before midday. You are only limited by your imagination!\n",
    "In this exercise, we will try a simple approach with only two features: the number of commits before midday and the number of commits after midday.\n",
    "• What you need to do is described in full details in the notebook.\n",
    "\n",
    "---\n",
    "\n",
    "Вы будете работать с машинным обучением сегодня и завтра. Сегодня мы рассмотрим основы, необходимые, чтобы не перегружать себя слишком большим объемом информации. На следующий день я расскажу о более сложных техниках. Так что следите за обновлениями!\n",
    "Прежде всего, машинное обучение можно разделить на контролируемое и неконтролируемое. При обучении с учителем вы хотите что-то предсказать. Для этого вы приводите примеры машин: набор функций и целевая переменная. Представьте, что вы хотите предсказать, понравится ли пользователю данный фильм. Характеристики (X) могут быть: жанр, год создания, бюджет, состав, режиссер и т. Д. Цель (y) будет нравится / не нравится. Такого рода задача - задача классификации. В задачах классификации y всегда категорично. Если ваша целевая переменная является непрерывной (например, рейтинг фильма), это называется проблемой регрессии.\n",
    "Для обучения без учителя не требуются метки (целевая переменная). Он ничего не предсказывает. Обычно это помогает лучше понять свои данные. Например, алгоритмы кластеризации помогают идентифицировать однородные группы наблюдений. Вы можете обнаружить, что можете разделить своих пользователей на 6 групп. И для каждой из этих групп создайте специальное предложение или рекомендацию. Не путайте это с классификацией. Вы не пытаетесь ничего предсказать. Вы просто смотрите на свои данные.\n",
    "Помимо алгоритмов кластеризации, обучение без учителя включает в себя алгоритмы уменьшения размерности. Они помогают сократить количество объектов или наблюдений. Это может быть полезно, если у вас их много, но у вас недостаточно ресурсов. Кроме того, они могут помочь вам найти некоторые скрытые функции и улучшить качество ваших алгоритмов в контролируемом обучении.\n",
    "\n",
    "\n",
    "Но хватит теории! Попробуем обучить нашего первого классификатора. Это будет двоичный классификатор, что означает, что целевая переменная имеет только два уникальных значения. Вы будете работать с набором данных за предыдущие дни. Это абсолютно нормально. Собственно, так работает наука о данных. Вы начинаете с описательного анализа и продолжаете анализировать некоторую базовую статистику. Затем вы идете дальше и проводите исследовательский анализ, рисуя различные графики, и, в результате, лучше понимаете свои данные. Только после этого вы переходите к предиктивному анализу, чтобы что-то спрогнозировать.\n",
    "В этом упражнении представьте следующую ситуацию (которая, кстати, довольно часто встречается). С какого-то момента в прошлом вы поняли, что чем больше данных вы соберете, тем лучше. И вы начали сохранять больше полей в журналах. Раньше вы собирали только время фиксации. Но с этого момента вы тоже начали собирать дату.\n",
    "Теперь вам нужно обучить классификатор, который может предсказать, было ли совершено какое-либо фиксирование в рабочие дни или в выходные. Тогда вы сможете использовать классификатор для маркировки коммитов в прошлом, когда вы не собирали данные.\n",
    "Каждый алгоритм машинного обучения с учителем требует как минимум двух аргументов: X и y. X - это список функций, а y - целевой столбец. Но каковы особенности?\n",
    "Как вы, несомненно, помните, у нас есть только такие журналы, как этот 2020-04-17 05: 19: 02.744528. Как мы можем использовать это, чтобы предсказать тип дня недели? Это творческая часть работы. Это называется функциональной инженерией. Вам необходимо извлечь эти функции из журналов. Что бы это могло быть? Помните, что наблюдение в этом задании - день? Итак, нам нужно извлечь то, что может как-то характеризовать дни. Что бы это могло быть? Это может быть, например, количество коммитов за день. Это может быть количество коммитов до полудня и после него. Или это также может быть процент коммитов, сделанных до полудня. Вы ограничены только вашим воображением!\n",
    "В этом упражнении мы попробуем простой подход с двумя функциями: количество коммитов до полудня и количество коммитов после полудня.\n",
    "• Все, что вам нужно сделать, подробно описано в блокноте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "# from pandas.plotting import scatter_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get the data from the file [`checker-timestamp.csv`](https://drive.google.com/file/d/1pooM4cITtG249msX3GK_6W0eEiblzAf5/view?usp=sharing).\n",
    "\n",
    "\n",
    "- Create a dataframe `df` with the columns: `date`, `am`, `pm`, `target`, where `date` is the date of the day, `am` is the number of the commits during the day before midday (integer), `pm` is the number of commits during the day after midday (integer), `target` is `weekend`/`working_day`.\n",
    "\n",
    "---\n",
    "\n",
    "- Получите данные из файла [`checker-timestamp.csv`] (https://drive.google.com/file/d/1pooM4cITtG249msX3GK_6W0eEiblzAf5/view?usp=sharing).\n",
    "\n",
    "\n",
    "- Создайте фрейм данных `df` со столбцами:` date`, `am`,` pm`, `target`, где `date` - это дата дня, `am` - количество коммитов в течение дня до полудня (целое число), `pm` - количество коммитов в течение дня после полудня (целое число), `target` - `weekend`/`working_day`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>date</th>\n",
       "      <th>target</th>\n",
       "      <th>part_of_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-17 05:19:02.744528</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>working_day</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-17 05:22:35.249331</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>working_day</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-17 05:22:45.549397</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>working_day</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-17 05:34:14.691200</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>working_day</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-17 05:34:24.422370</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>working_day</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3202</th>\n",
       "      <td>2020-05-21 20:19:06.872761</td>\n",
       "      <td>2020-05-21</td>\n",
       "      <td>working_day</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3203</th>\n",
       "      <td>2020-05-21 20:22:41.785725</td>\n",
       "      <td>2020-05-21</td>\n",
       "      <td>working_day</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3204</th>\n",
       "      <td>2020-05-21 20:22:41.877806</td>\n",
       "      <td>2020-05-21</td>\n",
       "      <td>working_day</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3205</th>\n",
       "      <td>2020-05-21 20:37:00.129678</td>\n",
       "      <td>2020-05-21</td>\n",
       "      <td>working_day</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3206</th>\n",
       "      <td>2020-05-21 20:37:00.290491</td>\n",
       "      <td>2020-05-21</td>\n",
       "      <td>working_day</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3207 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      timestamp        date       target part_of_day\n",
       "0    2020-04-17 05:19:02.744528  2020-04-17  working_day          am\n",
       "1    2020-04-17 05:22:35.249331  2020-04-17  working_day          am\n",
       "2    2020-04-17 05:22:45.549397  2020-04-17  working_day          am\n",
       "3    2020-04-17 05:34:14.691200  2020-04-17  working_day          am\n",
       "4    2020-04-17 05:34:24.422370  2020-04-17  working_day          am\n",
       "...                         ...         ...          ...         ...\n",
       "3202 2020-05-21 20:19:06.872761  2020-05-21  working_day          pm\n",
       "3203 2020-05-21 20:22:41.785725  2020-05-21  working_day          pm\n",
       "3204 2020-05-21 20:22:41.877806  2020-05-21  working_day          pm\n",
       "3205 2020-05-21 20:37:00.129678  2020-05-21  working_day          pm\n",
       "3206 2020-05-21 20:37:00.290491  2020-05-21  working_day          pm\n",
       "\n",
       "[3207 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checker_df = pd.read_csv(\"day08/data/checker_timestamp.csv\", parse_dates=['timestamp'])\n",
    "\n",
    "checker_df['date'] = checker_df.timestamp.dt.date\n",
    "\n",
    "checker_df['target'] = (\n",
    "    checker_df.timestamp.apply(lambda date: 'working_day' if pd.to_datetime(date).dayofweek < 5 else 'weekend')\n",
    ")\n",
    "\n",
    "checker_df['hour'] = pd.DatetimeIndex(checker_df.timestamp).hour\n",
    "\n",
    "checker_df['part_of_day'] = (\n",
    "    checker_df.hour.apply(lambda hour: 'am' if hour < 12 else 'pm')\n",
    ")\n",
    "\n",
    "checker_df.drop('hour', axis=1, inplace=True)\n",
    "\n",
    "checker_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/j4/d3f91n7j7qq97vh84088l9w40000gq/T/ipykernel_91820/2674885417.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.to_records()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    checker_df\n",
    "        .pivot_table(index=['date','target'], columns='part_of_day', values='timestamp', aggfunc='count')\n",
    ")\n",
    "\n",
    "# convert from pivot to normal state\n",
    "# https://stackoverflow.com/questions/43756052/transform-pandas-pivot-table-to-regular-dataframe\n",
    "\n",
    "# df.reset_index(inplace=True)\n",
    "# df.columns.name = None\n",
    "\n",
    "df = pd.DataFrame(df.to_records())\n",
    "\n",
    "for _ in ['am','pm']:\n",
    "    df[_] = df[_].fillna(0).apply(int)\n",
    "\n",
    "df = df[['date','am','pm','target']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a plot where `x` is am, `y` is pm, each dot is a day, working days and weekends must have different colors.\n",
    "\n",
    "\n",
    "- By looking at the graph do you think it will be easy to classify the days having those two features? Put your answer in the markdown cell in the end of that sectioin: \"yes, it is easy\" or \"no, it is not easy\".\n",
    "\n",
    "---\n",
    "\n",
    "Создайте график, где x - это утро, y - вечер, каждая точка - день, рабочие и выходные дни должны иметь разные цвета.\n",
    "Глядя на график, как вы думаете, будет ли легко классифицировать дни с этими двумя характеристиками? Поместите свой ответ в ячейку уценки в конце этого раздела: «да, это легко» или «нет, это непросто»."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,8))\n",
    "sns.scatterplot(data=df, x=\"am\", y=\"pm\", hue=\"target\", ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,8))\n",
    "\n",
    "df.query(\"target == 'weekend'\").plot.scatter(x='am', y='pm', c='DarkBlue', ax=ax, label='weekend')\n",
    "df.query(\"target == 'working_day'\").plot.scatter(x='am', y='pm', c='red', ax=ax, label='working_day')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no, it is not easy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train logistic regression on your data using `am` and `pm`, parameters are: `random state=21`, `fit_intercept=False`.\n",
    "- Make predictions for every day of your dataset and add them to your dataframe with the column name `predict`.\n",
    "- Save the dataframe into a file in the subfolder of the day `data` with the name `am_pm.csv`.\n",
    "- Draw another plot like you did before, but the color should be taken from the `predict`.\n",
    "- By looking at the graph do you think if it made good predictions? Put your answer in the markdown cell in the end of that section: \"yes, it is good\"; \"no, it is not good\".\n",
    "\n",
    "---\n",
    "\n",
    "- Обучите логистическую регрессию на ваших данных с помощью am и pm, параметры: random state = 21, fit_intercept = False.\n",
    "- Делайте прогнозы на каждый день для вашего набора данных и добавляйте их в свой фрейм данных с именем столбца «прогноз».\n",
    "- Сохраните фрейм данных в файл в подпапке дня `data` с именем` am_pm.csv`.\n",
    "- Нарисуйте еще один сюжет, как вы делали раньше, но цвет должен быть взят из «предсказать».\n",
    "- Глядя на график, как вы думаете, сделал ли он хорошие прогнозы? Поместите свой ответ в ячейку уценки в конце этого раздела: «Да, это хорошо»; «нет, это нехорошо»."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['am','pm']]\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(fit_intercept=False, random_state=21).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['predict'] = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/am_pm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,8))\n",
    "\n",
    "df.query(\"predict == 'weekend'\").plot.scatter(x='am', y='pm', c='DarkBlue', ax=ax, label='weekend')\n",
    "df.query(\"predict == 'working_day'\").plot.scatter(x='am', y='pm', c='red', ax=ax, label='working_day')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no, it is not good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculate `accuracy` for your predictions.\n",
    "- Calculate `accuracy` for the naive case when each of your prediction is the value of your most popular class of the day.\n",
    "- Comparing the accuracies do you think that the classifier made good predictions? Put your answer in the markdown cell in the end of the secion: \"yes, it is good\"; \"no, it is not good\".\n",
    "\n",
    "---\n",
    "\n",
    "- Расчет точности ваших прогнозов.\n",
    "- Вычислите \"точность\" для наивного случая, когда каждое ваше предсказание является значением вашего самого популярного класса дня.\n",
    "- Сравнивая точность, считаете ли вы, что классификатор сделал хорошие прогнозы? Напишите ответ в ячейку уценки в конце раздела: «да, хорошо»; «нет, это нехорошо»."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate accuracy for your predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y, df.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP, FP, TN, FN = 0, 0, 0, 0\n",
    "\n",
    "for predict, target in zip(df.predict.values, df.target.values):\n",
    "    if predict == 'weekend' and target == 'weekend':\n",
    "        TP += 1\n",
    "    elif predict == 'weekend' and target == 'working_day':\n",
    "        FP += 1\n",
    "    elif predict == 'working_day' and target == 'working_day':\n",
    "        TN += 1\n",
    "    elif predict == 'working_day' and target == 'weekend':\n",
    "        FP += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True positive (TP) = the number of cases correctly identified as patient\n",
    "\n",
    "False positive (FP) = the number of cases incorrectly identified as patient\n",
    "\n",
    "True negative (TN) = the number of cases correctly identified as healthy\n",
    "\n",
    "False negative (FN) = the number of cases incorrectly identified as healthy\n",
    "\n",
    "Accuracy: The accuracy of a test is its ability to differentiate the patient and healthy cases correctly. To estimate the accuracy of a test, we should calculate the proportion of true positive and true negative in all evaluated cases. Mathematically, this can be stated as:\n",
    "\n",
    "Accuracy=TP+TN / (TP+TN+FP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(TP+TN) / (TP+TN+FP+FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate `accuracy` for the naive case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['naive'] = df.target.value_counts().keys()[0]\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y, df.naive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no, it is not good"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
