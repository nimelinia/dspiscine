{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 08. Exercise 03\n",
    "# Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read the file `dayofweek.csv` to a dataframe.\n",
    "2. Using `train_test_split` with parameters `test_size=0.2`, `random_state=21` get `X_train`, `y_train`, `X_test`, `y_test`.\n",
    "3. Using, for example, `value_counts()` to check if the distribution of classes is similar in train and test.\n",
    "4. Use the additional parameter `stratify=` and check the distribution again, now it should be more or less similar in both datasets.\n",
    "\n",
    "\n",
    "1. Прочтите файл dayofweek.csv во фрейм данных.\n",
    "2. Используя train_test_split с параметрами test_size = 0.2, random_state = 21, получаем X_train, y_train, X_test, y_test.\n",
    "3. Используя, например, `value_counts ()`, чтобы проверить, одинаково ли распределение классов в обучении и тестировании.\n",
    "4. Используйте дополнительный параметр `stratify =` и снова проверьте распределение, теперь оно должно быть более или менее схожим в обоих наборах данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the file dayofweek.csv to a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>numTrials</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>user_0</th>\n",
       "      <th>user_1</th>\n",
       "      <th>user_10</th>\n",
       "      <th>user_11</th>\n",
       "      <th>user_12</th>\n",
       "      <th>user_13</th>\n",
       "      <th>...</th>\n",
       "      <th>lab02</th>\n",
       "      <th>lab03</th>\n",
       "      <th>lab03s</th>\n",
       "      <th>lab05s</th>\n",
       "      <th>laba04</th>\n",
       "      <th>laba04s</th>\n",
       "      <th>laba05</th>\n",
       "      <th>laba06</th>\n",
       "      <th>laba06s</th>\n",
       "      <th>project1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.788667</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.756764</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.724861</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.692958</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.661055</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  numTrials      hour  dayofweek  user_0  user_1  user_10  \\\n",
       "0           0  -0.788667 -2.562352          4     0.0     0.0      0.0   \n",
       "1           1  -0.756764 -2.562352          4     0.0     0.0      0.0   \n",
       "2           2  -0.724861 -2.562352          4     0.0     0.0      0.0   \n",
       "3           3  -0.692958 -2.562352          4     0.0     0.0      0.0   \n",
       "4           4  -0.661055 -2.562352          4     0.0     0.0      0.0   \n",
       "\n",
       "   user_11  user_12  user_13  ...  lab02  lab03  lab03s  lab05s  laba04  \\\n",
       "0      0.0      0.0      0.0  ...    0.0    0.0     0.0     0.0     0.0   \n",
       "1      0.0      0.0      0.0  ...    0.0    0.0     0.0     0.0     0.0   \n",
       "2      0.0      0.0      0.0  ...    0.0    0.0     0.0     0.0     0.0   \n",
       "3      0.0      0.0      0.0  ...    0.0    0.0     0.0     0.0     0.0   \n",
       "4      0.0      0.0      0.0  ...    0.0    0.0     0.0     0.0     0.0   \n",
       "\n",
       "   laba04s  laba05  laba06  laba06s  project1  \n",
       "0      0.0     0.0     0.0      0.0       1.0  \n",
       "1      0.0     0.0     0.0      0.0       1.0  \n",
       "2      0.0     0.0     0.0      0.0       1.0  \n",
       "3      0.0     0.0     0.0      0.0       1.0  \n",
       "4      0.0     0.0     0.0      0.0       1.0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/dayofweek.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using train_test_split with parameters test_size=0.2, random_state=21 get X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('dayofweek', axis=1), df['dayofweek'],\n",
    "                                                    test_size=0.2, random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Используя, например, `value_counts ()`, чтобы проверить, одинаково ли распределение классов в обучении и тестировании.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3    311\n",
       " 6    283\n",
       " 1    221\n",
       " 5    217\n",
       " 2    121\n",
       " 0    111\n",
       " 4     84\n",
       " Name: dayofweek, dtype: int64,\n",
       " 3    85\n",
       " 6    73\n",
       " 5    54\n",
       " 1    53\n",
       " 2    28\n",
       " 0    25\n",
       " 4    20\n",
       " Name: dayofweek, dtype: int64,\n",
       " 0    0.225225\n",
       " 1    0.239819\n",
       " 2    0.231405\n",
       " 3    0.273312\n",
       " 4    0.238095\n",
       " 5    0.248848\n",
       " 6    0.257951\n",
       " Name: dayofweek, dtype: float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(), y_test.value_counts(), y_test.value_counts() / y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Используйте дополнительный параметр `stratify =` и снова проверьте распределение, теперь оно должно быть более или менее схожим в обоих наборах данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('dayofweek', axis=1), df['dayofweek'],\n",
    "                                                    test_size=0.2, random_state=12, stratify =df['dayofweek'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3    316\n",
       " 6    285\n",
       " 1    219\n",
       " 5    217\n",
       " 2    119\n",
       " 0    109\n",
       " 4     83\n",
       " Name: dayofweek, dtype: int64,\n",
       " 3    80\n",
       " 6    71\n",
       " 1    55\n",
       " 5    54\n",
       " 2    30\n",
       " 0    27\n",
       " 4    21\n",
       " Name: dayofweek, dtype: int64,\n",
       " 3    0.253165\n",
       " 6    0.249123\n",
       " 1    0.251142\n",
       " 5    0.248848\n",
       " 2    0.252101\n",
       " 0    0.247706\n",
       " 4    0.253012\n",
       " Name: dayofweek, dtype: float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(), y_test.value_counts(), y_test.value_counts() / y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Baseline models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train exactly the same baseline models from the previous exercise and calculate the accuracies using the test dataset with stratification.\n",
    "2. Did all the models show the similar values of the metric? Which one has the largest difference comparing the current exercise and the previous? Put the answer to the markdown cell in the end of the section.\n",
    "\n",
    "\n",
    "1. Обучите точно такие же базовые модели из предыдущего упражнения и рассчитайте точность, используя тестовый набор данных со стратификацией.\n",
    "2. Все ли модели показали одинаковые значения метрики? Какое из упражнений имеет наибольшее различие по сравнению с текущим упражнением и предыдущим? Поместите ответ в ячейку уценки в конце раздела."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5384615384615384"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model = LogisticRegression(fit_intercept=False, random_state=21)\n",
    "log_model.fit(X_train, y_train)\n",
    "accuracy_score(y_test, log_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svm = sklearn.svm.SVC(random_state = 21, probability=True, kernel='linear')\n",
    "model_svm.fit(X_train, y_train)\n",
    "accuracy_score(y_test, model_svm.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_model_1 = DecisionTreeClassifier(max_depth = 4, random_state = 21)\n",
    "dtc_model_1.fit(X_train, y_train)\n",
    "accuracy_score(y_test, dtc_model_1.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_model_1= RandomForestClassifier(n_estimators = 100, max_depth = 25, random_state = 21)\n",
    "rfc_model_1.fit(X_train, y_train)\n",
    "accuracy_score(y_test, rfc_model_1.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Все ли модели показали одинаковые значения метрики?\n",
    "\n",
    "* Какое из упражнений имеет наибольшее различие по сравнению с текущим упражнением и предыдущим? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Нет. Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Crossvalidation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could play with parameters of the model trying to achive a better accuracy on the test dataset, but it is a bad practice. It leads us again to overfitting. Test dataset is only for checking quality of a final model.\n",
    "\n",
    "But there is another way of solving the problem – crossvalidation. It does not use test dataset, but creates one more split of train dataset. Again, there are different ways of doing it, but the common thing is that there is a validation dataset that is used for hyperparameters optimization.\n",
    "\n",
    "\n",
    "Мы могли бы поиграть с параметрами модели, пытаясь добиться большей точности на тестовом наборе данных, но это плохая практика. Это снова приводит нас к переоснащению. Набор тестовых данных предназначен только для проверки качества окончательной модели.\n",
    "\n",
    "Но есть еще один способ решения проблемы - перекрестная проверка. Он не использует тестовый набор данных, но создает еще одно разделение набора данных поезда. Опять же, есть разные способы сделать это, но общим является то, что существует набор данных проверки, который используется для оптимизации гиперпараметров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using `cross_val_score` with `cv=10` calculate the mean accuracy and standard deviation for every model that you used before (logreg with `solver='liblinear'`, SVC, decision tree, random forest).\n",
    "\n",
    "1. Используя cross_val_score с cv = 10, вычислите среднюю точность и стандартное отклонение для каждой модели, которую вы использовали ранее (logreg с solver = 'liblinear`, SVC, дерево решений, случайный лес)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = LogisticRegression(fit_intercept=False, random_state=21, solver='liblinear')\n",
    "cvs_log_model = cross_val_score(log_model, df.drop('target', axis=1), df['target'], cv=10)\n",
    "cvs_log_model.mean(), cvs_log_model.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs_model_svm = cross_val_score(model_svm, df.drop('target', axis=1), df['target'], cv=10)\n",
    "cvs_model_svm.mean(), cvs_model_svm.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs_dtc_model_1 = cross_val_score(dtc_model_1, df.drop('target', axis=1), df['target'], cv=10)\n",
    "cvs_dtc_model_1.mean(), cvs_dtc_model_1.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs_rfc_model_1 = cross_val_score(rfc_model_1, df.drop('target', axis=1), df['target'], cv=10)\n",
    "cvs_rfc_model_1.mean(), cvs_rfc_model_1.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Choose the best model and play a little bit with the parameters on cross-validation, find a good enough parameter or a combination of the parameters.\n",
    "2. Calculate the accuracy for the final model on the test dataset.\n",
    "3. Draw a plot that displays the top-10 most  important features for that model.\n",
    "4. Save the model using `joblib`.\n",
    "5. Load the model, make predictions for the test dataset and calculate the accuracy.\n",
    "\n",
    "\n",
    "1. Выберите лучшую модель и немного поиграйте с параметрами перекрестной проверки, найдите достаточно хороший параметр или комбинацию параметров.\n",
    "2. Рассчитайте точность окончательной модели на тестовом наборе данных.\n",
    "3. Нарисуйте график, отображающий 10 самых важных характеристик этой модели.\n",
    "4. Сохраните модель с помощью `joblib`.\n",
    "5. Загрузите модель, сделайте прогнозы для тестового набора данных и рассчитайте точность."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберите лучшую модель и немного поиграйте с параметрами перекрестной проверки, найдите достаточно хороший параметр или комбинацию параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs_rfc_model_1 = cross_val_score(rfc_model_1, df.drop('target', axis=1),\n",
    "                                  df['target'], cv=5, n_jobs =-1, scoring = 'f1_weighted')\n",
    "cvs_rfc_model_1.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассчитайте точность окончательной модели на тестовом наборе данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_model_1= RandomForestClassifier(n_estimators = 100, max_depth = 25, random_state = 21)\n",
    "rfc_model_1.fit(X_train, y_train)\n",
    "accuracy_score(y_test, rfc_model_1.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нарисуйте график, отображающий 10 самых важных характеристик этой модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_barh(coef, names, top_n, sums= True):\n",
    "    if sums:\n",
    "        mas = np.abs(coef).sum(axis=0)\n",
    "        top_feat = sorted(np.abs(mas), reverse=True)[:top_n]\n",
    "    else:\n",
    "        mas = np.abs(coef)\n",
    "        top_feat = sorted(np.abs(coef), reverse=True)[:top_n]\n",
    "        \n",
    "    index = mas.argsort()[-top_n:][::-1]\n",
    "    df = pd.DataFrame({'lab': names[index], 'val': top_feat})\n",
    "    ax = df.plot.barh(x='lab', y='val', figsize=(15,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_barh(rfc_model_1.feature_importances_, X_train.columns, 10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраните модель с помощью joblib.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '../data/finalized_model.sav'\n",
    "joblib.dump(rfc_model_1, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите модель, сделайте прогнозы для тестового набора данных и рассчитайте точность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
